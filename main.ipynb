{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import wget\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'us-counties.csv' does not exist: b'us-counties.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-eb81704a9d4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcounty_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"us-counties.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'us-counties.csv' does not exist: b'us-counties.csv'"
     ]
    }
   ],
   "source": [
    "county_data = pd.read_csv(\"us-counties.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "nulls = county_data[county_data.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "nulls.to_csv(\"nulls.csv\")\n",
    "# All rows where FIPS is null. This consists of (a) New York City (all reported as one unit), (b) various Unknowns. \n",
    "# See NYT documentation on geographical exceptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 20200201\n",
      "Downloading 20200202\n",
      "Downloading 20200203\n",
      "Downloading 20200204\n",
      "Downloading 20200205\n",
      "Downloading 20200206\n",
      "Downloading 20200207\n",
      "Downloading 20200208\n",
      "Downloading 20200209\n",
      "Downloading 20200210\n",
      "Downloading 20200211\n",
      "Downloading 20200212\n",
      "Downloading 20200213\n",
      "Downloading 20200214\n",
      "Downloading 20200215\n",
      "Downloading 20200216\n",
      "Downloading 20200217\n",
      "Downloading 20200218\n",
      "Downloading 20200219\n",
      "Downloading 20200220\n",
      "Downloading 20200221\n",
      "Downloading 20200222\n",
      "Downloading 20200223\n",
      "Downloading 20200224\n",
      "Downloading 20200225\n",
      "Downloading 20200226\n",
      "Downloading 20200227\n",
      "Downloading 20200228\n",
      "Downloading 20200229\n",
      "No file for date 20200230\n",
      "No file for date 20200231\n",
      "Downloading 20200301\n",
      "Downloading 20200302\n",
      "Downloading 20200303\n",
      "Downloading 20200304\n",
      "Downloading 20200305\n",
      "Downloading 20200306\n",
      "Downloading 20200307\n",
      "Downloading 20200308\n",
      "Downloading 20200309\n",
      "Downloading 20200310\n",
      "Downloading 20200311\n",
      "Downloading 20200312\n",
      "Downloading 20200313\n",
      "Downloading 20200314\n",
      "Downloading 20200315\n",
      "Downloading 20200316\n",
      "Downloading 20200317\n",
      "Downloading 20200318\n",
      "Downloading 20200319\n",
      "Downloading 20200320\n",
      "Downloading 20200321\n",
      "Downloading 20200322\n",
      "Downloading 20200323\n",
      "Downloading 20200324\n",
      "Downloading 20200325\n",
      "Downloading 20200326\n",
      "Downloading 20200327\n",
      "Downloading 20200328\n",
      "Downloading 20200329\n",
      "Downloading 20200330\n",
      "Downloading 20200331\n",
      "Downloading 20200401\n",
      "Downloading 20200402\n",
      "Downloading 20200403\n",
      "Downloading 20200404\n",
      "Downloading 20200405\n",
      "Downloading 20200406\n",
      "Downloading 20200407\n",
      "Downloading 20200408\n",
      "Downloading 20200409\n",
      "Downloading 20200410\n",
      "Downloading 20200411\n",
      "Downloading 20200412\n",
      "Downloading 20200413\n",
      "Downloading 20200414\n",
      "Downloading 20200415\n",
      "Downloading 20200416\n",
      "Downloading 20200417\n",
      "Downloading 20200418\n",
      "Downloading 20200419\n",
      "Downloading 20200420\n",
      "Downloading 20200421\n",
      "Downloading 20200422\n",
      "Downloading 20200423\n",
      "Downloading 20200424\n",
      "Downloading 20200425\n",
      "Downloading 20200426\n",
      "Downloading 20200427\n",
      "Downloading 20200428\n",
      "Downloading 20200429\n",
      "Downloading 20200430\n",
      "No file for date 20200431\n",
      "Downloading 20200501\n",
      "Downloading 20200502\n",
      "Downloading 20200503\n",
      "Downloading 20200504\n",
      "Downloading 20200505\n",
      "Downloading 20200506\n",
      "Downloading 20200507\n",
      "Downloading 20200508\n",
      "Downloading 20200509\n",
      "Downloading 20200510\n",
      "Downloading 20200511\n",
      "Downloading 20200512\n",
      "Downloading 20200513\n",
      "Downloading 20200514\n",
      "Downloading 20200515\n",
      "Downloading 20200516\n",
      "Downloading 20200517\n",
      "Downloading 20200518\n",
      "Downloading 20200519\n",
      "Downloading 20200520\n",
      "No file for date 20200521\n",
      "No file for date 20200522\n",
      "No file for date 20200523\n",
      "No file for date 20200524\n",
      "No file for date 20200525\n",
      "No file for date 20200526\n",
      "No file for date 20200527\n",
      "No file for date 20200528\n",
      "No file for date 20200529\n",
      "No file for date 20200530\n",
      "No file for date 20200531\n"
     ]
    }
   ],
   "source": [
    "# Download daily data files -- did this on 5/20. Saved as .txt files in /data\n",
    "\n",
    "for m in range(4):\n",
    "    for d in range(31):\n",
    "        month = str(m+2).zfill(2)\n",
    "        day = str(d+1).zfill(2)\n",
    "        date = \"2020\"+month+day\n",
    "        url = \"https://s3-us-west-1.amazonaws.com//files.airnowtech.org/airnow/2020/\"+date+\"/daily_data_v2.dat\"\n",
    "        try:\n",
    "            wget.download(url, \"./data/\"+date+\".txt\")\n",
    "            print('Downloading', date)\n",
    "        except:\n",
    "            print('No file for date', date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make DFs from .txt files\n",
    "# date_dfs is a dictionary of DFs where keys are dates in MMDD format\n",
    "\n",
    "# DF column values: \"aqsid\" = site ID, first 5 digits are FIPS code; \n",
    "# \"period\" = averaging period (either peak 1-hr, peak 8-hr average, or 24-hr average);\n",
    "# \"aqi_value\" = 8-hr or 24-hr AQI value, -999 = peak 1-hr ozone or peak 24-hr SO2; \"aqi_category\" = 0=good etc.;\n",
    "# \"aqsid_full\" = AQS site ID preceded by 3-digit country code\n",
    "\n",
    "date_dfs = {}\n",
    "allfiles = os.listdir('data')[1:]\n",
    "for filename in allfiles:\n",
    "    date = filename[4:8]\n",
    "    df = pd.read_csv('data/'+filename, sep=\"|\", header=None)\n",
    "    df.columns = [\"date\",\"aqsid\",\"sitename\",\"parameter\",\"units\",\"value\",\"period\",\"source\",\"aqi_value\",\"aqi_category\",\"latitude\",\"longitude\",\"aqsid_full\"]\n",
    "    df['fips'] = df['aqsid'].str.slice(stop=5)  # add FIPS column based on first 5 digits of AQSID\n",
    "    del df['aqsid']\n",
    "    del df['source']\n",
    "    del df['latitude']\n",
    "    del df['longitude']\n",
    "    df = df.loc[df['aqsid_full'].str[:3] == '840']   # delete non-US rows \n",
    "    del df['aqsid_full']\n",
    "    df.to_csv('air_quality_tables/'+filename[:-3]+'csv')\n",
    "    date_dfs[date] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_dfs['0520'] = None   # dropped today's table because it contained data from 5/18 for some reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = pd.concat(date_dfs.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = master_df['date'].str\n",
    "newdates = \"20\"+dates[6:8]+\"-\"+dates[3:5]+\"-\"+dates[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df['date'] = newdates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df.to_csv('all_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>sitename</th>\n",
       "      <th>units</th>\n",
       "      <th>value</th>\n",
       "      <th>period</th>\n",
       "      <th>aqi_value</th>\n",
       "      <th>aqi_category</th>\n",
       "      <th>fips</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parameter</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>CO-8hr</td>\n",
       "      <td>17375</td>\n",
       "      <td>17375</td>\n",
       "      <td>17375</td>\n",
       "      <td>17375</td>\n",
       "      <td>17375</td>\n",
       "      <td>17375</td>\n",
       "      <td>17375</td>\n",
       "      <td>17375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>OZONE-1HR</td>\n",
       "      <td>111450</td>\n",
       "      <td>111450</td>\n",
       "      <td>111450</td>\n",
       "      <td>111450</td>\n",
       "      <td>111450</td>\n",
       "      <td>111450</td>\n",
       "      <td>111450</td>\n",
       "      <td>111450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>OZONE-8HR</td>\n",
       "      <td>106931</td>\n",
       "      <td>106931</td>\n",
       "      <td>106931</td>\n",
       "      <td>106931</td>\n",
       "      <td>106931</td>\n",
       "      <td>106931</td>\n",
       "      <td>106931</td>\n",
       "      <td>106931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>PM10-24hr</td>\n",
       "      <td>29709</td>\n",
       "      <td>29709</td>\n",
       "      <td>29709</td>\n",
       "      <td>29709</td>\n",
       "      <td>29709</td>\n",
       "      <td>29709</td>\n",
       "      <td>29709</td>\n",
       "      <td>29709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>PM2.5-24hr</td>\n",
       "      <td>89894</td>\n",
       "      <td>89892</td>\n",
       "      <td>89894</td>\n",
       "      <td>89894</td>\n",
       "      <td>89894</td>\n",
       "      <td>89894</td>\n",
       "      <td>89894</td>\n",
       "      <td>89894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>SO2-24HR</td>\n",
       "      <td>25557</td>\n",
       "      <td>25557</td>\n",
       "      <td>25557</td>\n",
       "      <td>25557</td>\n",
       "      <td>25557</td>\n",
       "      <td>25557</td>\n",
       "      <td>25557</td>\n",
       "      <td>25557</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              date  sitename   units   value  period  aqi_value  aqi_category  \\\n",
       "parameter                                                                       \n",
       "CO-8hr       17375     17375   17375   17375   17375      17375         17375   \n",
       "OZONE-1HR   111450    111450  111450  111450  111450     111450        111450   \n",
       "OZONE-8HR   106931    106931  106931  106931  106931     106931        106931   \n",
       "PM10-24hr    29709     29709   29709   29709   29709      29709         29709   \n",
       "PM2.5-24hr   89894     89892   89894   89894   89894      89894         89894   \n",
       "SO2-24HR     25557     25557   25557   25557   25557      25557         25557   \n",
       "\n",
       "              fips  \n",
       "parameter           \n",
       "CO-8hr       17375  \n",
       "OZONE-1HR   111450  \n",
       "OZONE-8HR   106931  \n",
       "PM10-24hr    29709  \n",
       "PM2.5-24hr   89894  \n",
       "SO2-24HR     25557  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df.groupby(['parameter']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = master_df['parameter'].unique().tolist()\n",
    "ozone1 = master_df[master_df['parameter']==names[0]]\n",
    "ozone8 = master_df[master_df['parameter']==names[1]]\n",
    "pm10 = master_df[master_df['parameter']==names[2]]\n",
    "pm25 = master_df[master_df['parameter']==names[3]]\n",
    "co8 = master_df[master_df['parameter']==names[4]]\n",
    "so2 = master_df[master_df['parameter']==names[5]]\n",
    "\n",
    "# deleted unneeded columns and saved each as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table of FIPS codes to county/state\n",
    "\n",
    "fips = pd.read_html('https://www.nrcs.usda.gov/wps/portal/nrcs/detail/national/home/?cid=nrcs143_013697')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fips = fips.drop(3232) # last row was gibberish\n",
    "# did some other massaging which I deleted the code for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "fips.to_csv('fips.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "fips = pd.read_csv('fips.csv', dtype={'fips':\"str\"})\n",
    "del fips['Unnamed: 0']\n",
    "\n",
    "# for some reason the CSV loses leading zeroes in the fips column; \n",
    "# opening like this fixes it for the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
